{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import glob,scipy\n",
    "import numpy as np\n",
    "import scipy.ndimage as snd\n",
    "from scipy import optimize\n",
    "import seaborn as sb\n",
    "from astropy.io import fits\n",
    "\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First grab a list of all filenames 3 directories deep inside of the defined root directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array(['./Data/2018-05-17/2ndCal/8s.00000093.Mouse click position.fit',\n",
      "       './Data/2018-05-17/2ndCal/8s.00000094.Mouse click position.fit',\n",
      "       './Data/2018-05-17/2ndCal/8s.00000095.HIP 61958.fit',\n",
      "       './Data/2018-05-17/3rdCal/10sR.00000096.HIP 61958.fit',\n",
      "       './Data/2018-05-17/3rdCal/10sR.00000097.HIP 61958.fit'], \n",
      "      dtype='|S61'), '...', array(['./Data/2018-05-17/M51/180sHa.00000089.M 51.fit',\n",
      "       './Data/2018-05-17/M51/300sHa.00000090.M 51.fit',\n",
      "       './Data/2018-05-17/M51/300sHa.00000091.M 51.fit',\n",
      "       './Data/2018-05-17/M51/300sHa.00000092.M 51.fit',\n",
      "       './Data/2018-05-17/M51/30s.00000079.M 51.fit'], \n",
      "      dtype='|S61'))\n",
      "['2ndCal' '3rdCal' 'Bias' 'Dark' 'Feige66' 'Flat' 'Focusing' 'M51']\n"
     ]
    }
   ],
   "source": [
    "rootdir='.'\n",
    "all_fits_filenames=np.array(glob.glob(rootdir+'/Data/2018-05-17/*/*.fit'))\n",
    "folder_names=np.array([fooname.split('/')[-2] for fooname in all_fits_filenames])\n",
    "print (all_fits_filenames[:5],\"...\",all_fits_filenames[-5:])\n",
    "print (unique(folder_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, using the image headers read in from fits.getheader, sort the exposures into flats, biases, science frames, etc., as well as reading in the filter names and exposure times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Our exposure types', array(['Bias Frame', 'Dark Frame', 'Flat Field', 'Light Frame'], \n",
      "      dtype='|S11'))\n",
      "('Number of bias frames', 20)\n",
      "('Number of darks and exposure times', '8', array([ 200.]))\n",
      "('Flat filters and exposure times', array(['B', 'H-a', 'I', 'R', 'V'], \n",
      "      dtype='|S3'), array([   1.,    5.,   10.,   11.,   14.,   38.,   90.,  130.]))\n",
      "('Object filters exposed and exposure times', array(['B', 'H-a', 'I', 'R', 'V'], \n",
      "      dtype='|S3'), array([  30.,  100.,  120.,  150.,  180.,  300.]))\n"
     ]
    }
   ],
   "source": [
    "all_exp_types = np.array([fits.getheader(fooname)[\"IMAGETYP\"] for fooname in all_fits_filenames])\n",
    "print (\"Our exposure types\",unique(all_exp_types))\n",
    "\n",
    "bias_filenames = all_fits_filenames[np.where(all_exp_types=='Bias Frame')]\n",
    "print (\"Number of bias frames\",len(bias_filenames))\n",
    "\n",
    "dark_filenames = np.sort(all_fits_filenames[np.where(all_exp_types=='Dark Frame')])\n",
    "dark_exptimes=np.array([fits.getheader(fooname)[\"EXPTIME\"] for fooname in dark_filenames])\n",
    "print (\"Number of darks and exposure times\",str(len(dark_filenames)),unique(dark_exptimes))\n",
    "\n",
    "flat_filenames = all_fits_filenames[np.where(all_exp_types=='Flat Field')]\n",
    "flat_filter_names=np.array([fits.getheader(fooname)[\"FILTER\"] for fooname in flat_filenames])\n",
    "flat_exptimes=np.array([fits.getheader(fooname)[\"EXPTIME\"] for fooname in flat_filenames])\n",
    "print (\"Flat filters and exposure times\",unique(flat_filter_names),unique(flat_exptimes))\n",
    "\n",
    "\n",
    "object_folder_name='M51'\n",
    "object_filenames= all_fits_filenames[np.where((folder_names==object_folder_name))]# | (folder_names=='objectB'))]\n",
    "\n",
    "object_filter_names=np.array([fits.getheader(fooname)[\"FILTER\"] for fooname in object_filenames])\n",
    "object_exptimes=np.array([fits.getheader(fooname)[\"EXPTIME\"] for fooname in object_filenames])\n",
    "print (\"Object filters exposed and exposure times\",unique(object_filter_names),unique(object_exptimes))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's make a median bias, flat, and dark frame. Use the definition below to stack them up and take the median value for each pixel in the stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# warning, reading in hundreds of bias frames may slow/kill your computer, index the filename array\n",
    "#  if you want to use less than all\n",
    "\n",
    "def median_combine(filelist):\n",
    "    allimgs=[]\n",
    "    for filename in filelist: allimgs.append(fits.getdata(filename))\n",
    "    allimgs=np.array(allimgs)\n",
    "    medianimg=np.median(allimgs,axis=0)\n",
    "    return medianimg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['R', 'R', 'R', 'H-a', 'H-a', 'H-a', 'V', 'V', 'V', 'B', 'B', 'B',\n",
       "        'V', 'V', 'V', 'I', 'I', 'I'], \n",
       "       dtype='|S3'),\n",
       " array([  11.,   11.,   11.,  130.,  130.,  130.,   14.,   14.,   14.,\n",
       "          38.,   38.,   38.,    1.,    5.,   10.,   90.,   90.,   90.]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flat_filter_names,flat_exptimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rootdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "thefilt='V'\n",
    "flat_time=10\n",
    "\n",
    "median_flat=median_combine(flat_filenames[np.where((flat_filter_names==thefilt) & (flat_exptimes==flat_time))])\n",
    "fits.writeto(rootdir+thefilt+'-median_flat.fits',median_flat,clobber=True)   #clobber will overwrite old images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda/lib/python2.7/site-packages/numpy/core/fromnumeric.py:2889: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/Applications/anaconda/lib/python2.7/site-packages/numpy/core/_methods.py:80: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "median_bias=median_combine(bias_filenames[:50])   # note that I take only the first 50 biases, to save time\n",
    "fits.writeto(rootdir+'median_bias.fits',median_bias,clobber=True)\n",
    "\n",
    "dark_time=100\n",
    "median_dark=median_combine(dark_filenames[:][where(dark_exptimes==dark_time)])\n",
    "median_dark=(median_dark-median_bias)/dark_time*1.0\n",
    "fits.writeto(rootdir+'median_dark.fits',median_dark,clobber=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display the median flat, bias, and dark. Note the lack of hot pixels in the 2014 data (when the camera could be properly cooled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(median_flat,vmax=np.median(median_flat)+3*np.std(median_flat),cmap=plt.cm.coolwarm)\n",
    "plt.title('Median flat - '+thefilt,fontsize=25)\n",
    "plt.colorbar()\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(median_bias,vmax=np.median(median_bias)+3*np.std(median_bias),cmap=plt.cm.RdBu_r)\n",
    "plt.title('Median bias frame',fontsize=25)\n",
    "plt.colorbar()\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(median_dark,vmax=np.median(median_dark)+3*np.std(median_dark),cmap=plt.cm.spring),colorbar()\n",
    "plt.title('Median dark frame',fontsize=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's reduce the science frames using standard intrument signature removal. Note we subtract the dark from the science, and divide by a normalized flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reduce_raw_science_frames(science_filelist,median_bias,median_flat,median_dark):\n",
    "    allreducedimgs=[]\n",
    "    normed_flat=(median_flat-median_bias)/np.median(median_flat-median_bias)\n",
    "    for filename in science_filelist: \n",
    "        science_frame=fits.getdata(filename)\n",
    "        reduced_frame=(science_frame-median_dark-median_bias)/normed_flat\n",
    "        allreducedimgs.append(reduced_frame)\n",
    "    allreducedimgs=np.array(allreducedimgs)\n",
    "    return allreducedimgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in the raw science frames and reduce them using the above definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['B', 'B', 'R', 'R', 'I', 'I', 'I', 'V', 'V', 'H-a', 'H-a', 'H-a',\n",
       "        'H-a', 'B'], \n",
       "       dtype='|S3'),\n",
       " array([ 100.,  100.,  120.,  120.,  150.,  150.,  150.,  150.,  150.,\n",
       "         180.,  300.,  300.,  300.,   30.]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "object_filter_names,object_exptimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "thefilt='V'\n",
    "object_time=60\n",
    "science_filenames=np.sort(object_filenames[np.where((object_filter_names==thefilt) & (object_exptimes==object_time))])\n",
    "science_filenames=science_filenames\n",
    "print science_filenames\n",
    "science_reduced = reduce_raw_science_frames(science_filenames,median_bias,median_flat,median_dark*object_time)\n",
    "science_exptimes=np.array([fits.getheader(fooname)[\"EXPTIME\"] for fooname in science_filenames])\n",
    "print science_exptimes\n",
    "for i in range(len(science_reduced)):\n",
    "    fits.writeto(science_filenames[i].replace('.fit','-'+thefilt+'-reduced.fits'),science_reduced[i],\n",
    "                   clobber=True,header=fits.getheader(science_filenames[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What do the pixel values of the reduced frames look like? Note there is a sky level, which provides a noisy minimum to all of the reduced pixel values. Find it by taking a histogram of the pixel values and taking the pixel value which is at the maximum of the histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda/lib/python2.7/site-packages/matplotlib/axes/_axes.py:545: UserWarning: No labelled objects found. Use label='...' kwarg on individual plots.\n",
      "  warnings.warn(\"No labelled objects found. \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x119508650>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABDAAAAIzCAYAAAD20OmCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1194c5350>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(18,9))\n",
    "skylevels=[]\n",
    "for i in range(len(science_reduced)):\n",
    "    numpix,aduvals=np.histogram(science_reduced[i].flatten(),bins=1000,range=[-1e3,5e3])\n",
    "    skylevel=aduvals[where(numpix==numpix.max())][0]\n",
    "    skylevels.append(skylevel)\n",
    "    plt.plot(aduvals[:-1],numpix,label=str(science_filenames[i].split('/')[-1]))\n",
    "    plt.axvline(skylevel,color='k')\n",
    "plt.xlabel('pix val',fontsize=20)\n",
    "plt.ylabel('number of pixels',fontsize=20)\n",
    "plt.yscale('log')\n",
    "plt.legend()\n",
    "print (skylevels)\n",
    "plt.title('Histogram of reduced '+thefilt+' frame pixel values',fontsize=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show an example of the difference between reduced and unreduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-a27d9c3d7634>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtestnum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m  \u001b[0;31m#the file number to show comparison plot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mnstd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0munreduced\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetdata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscience_filenames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtestnum\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m121\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "testnum=0  #the file number to show comparison plot\n",
    "nstd=4\n",
    "unreduced=fits.getdata(science_filenames[testnum])\n",
    "figure(figsize=(20,8))\n",
    "plt.subplot(121)\n",
    "vmin_unred=np.median(median_bias)+skylevels[testnum]\n",
    "plt.imshow(unreduced,cmap=cm.Greys,vmin=vmin_unred,vmax=vmin_unred+nstd*np.sqrt(skylevels[testnum]))\n",
    "plt.colorbar()\n",
    "plt.subplot(122)\n",
    "plt.imshow(science_reduced[testnum],cmap=cm.Greys,vmin=skylevels[testnum],vmax=skylevels[testnum]+nstd*np.sqrt(skylevels[testnum]))\n",
    "plt.colorbar()\n",
    "plt.suptitle('The difference between reduced and unreduced',fontsize=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's find some objects in the field, using a simplified object & centroid finder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_object_centroids_filterbysize(img,threshold,minsize):\n",
    "    labels, num = snd.label(img > threshold, np.ones((3,3)))     # scipy labels/segments the image using a threshold\n",
    "    centers = snd.center_of_mass(img, labels, range(1,num+1))    # scipy calculates the center of mass on the labeled img\n",
    "    x = array(centers)[:,1]\n",
    "    y = array(centers)[:,0]\n",
    "    slices=snd.find_objects(labels)\n",
    "    xs=np.array([objlabel[1].stop-objlabel[1].start for objlabel in slices])  # takes the min and max label slices\n",
    "    ys=np.array([objlabel[0].stop-objlabel[0].start for objlabel in slices])  #  to find a rough object size\n",
    "\n",
    "    maxsize=1025    # I hardcoded this in so that some spurious objects would be skipped. Change/delete if you like\n",
    "    bigenough=np.where((xs>minsize) & (ys>minsize) & (xs<maxsize) & (ys<maxsize))\n",
    "    xc,yc=x[bigenough],y[bigenough]\n",
    "    xs,ys=xs[bigenough],ys[bigenough]\n",
    "    \n",
    "    print (str(len(xc))+' objects found')\n",
    "    return xc,yc,xs,ys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test out the object finder on a single image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-c03a0f91d428>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mimgnum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mnstd_aboveskynoise\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mthreshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskylevels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimgnum\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mnstd_aboveskynoise\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mskylevels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimgnum\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# decide on a threshold using the sky noise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mminsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "imgnum=0\n",
    "nstd_aboveskynoise=12\n",
    "threshold=skylevels[imgnum]+nstd_aboveskynoise*np.sqrt(skylevels[imgnum])   # decide on a threshold using the sky noise\n",
    "minsize=2\n",
    "\n",
    "xfoo,yfoo,xsfoo,ysfoo=find_object_centroids_filterbysize(science_reduced[imgnum],threshold,minsize)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(20,20))\n",
    "plt.imshow(science_reduced[imgnum],cmap=cm.Greys,vmin=0,vmax=1.5*threshold)\n",
    "plt.plot(xfoo,yfoo,'rs',mfc='None',markersize=20,markeredgecolor='b',markeredgewidth=2)\n",
    "axis([0,1024,0,1024])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Just a little definition which can grab postage stamps of objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_stamp(img,starx,stary,ws):\n",
    "    xlo,xhi,ylo,yhi=int(starx-ws),int(starx+ws),int(stary-ws),int(stary+ws)\n",
    "    xmin,ymin=0,0\n",
    "    xmax,ymax=np.shape(img)\n",
    "    if xlo<xmin: xlo=xmin\n",
    "    if xhi>xmax: xhi=xmax\n",
    "    if ylo<ymin: ylo=ymin\n",
    "    if yhi>ymax: yhi=ymax\n",
    "    return img[ylo:yhi,xlo:xhi]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(xfoo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objnum=11\n",
    "ws=30\n",
    "stamp=get_stamp(science_reduced[imgnum],xfoo[objnum],yfoo[objnum],ws)\n",
    "plt.imshow(stamp,interpolation='None',vmin=0,vmax=1.5*threshold)\n",
    "xcfoo,ycfoo=ws+xfoo[objnum]-floor(xfoo[objnum]),ws+yfoo[objnum]-floor(yfoo[objnum])\n",
    "plot(xcfoo,ycfoo,'wo')\n",
    "plt.colorbar()\n",
    "axis([0,ws*2,0,ws*2])\n",
    "plt.title('a sample star')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ns=1  # number of standard deviations from the mean to consider\n",
    "m,s=mean(stamp[stamp<1500]),std(stamp[stamp<1500])\n",
    "#gpix=np.where((stamp>m-ns*s) & (stamp<m+ns*s))[0]\n",
    "#m,s=mean(stamp[gpix]),np.std(stamp[gpix])\n",
    "axvline(m-s),axvline(m+s),axvline(m,color='r')\n",
    "hist(stamp.flatten(),bins=100,range=[m-ns*s,m+ns*s],histtype='stepfilled',color='g',alpha=.3)\n",
    "xlabel('ADU of background')\n",
    "ylabel('Number of pixels')\n",
    "print (m,s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now find objects in all the reduced frames, again using the sky noise from each reduced image as a threshold. Plot all the centroids detected in each image to illustrate the dithering that occurs between frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nstd_aboveskynoise=10\n",
    "thresholds=skylevels+nstd_aboveskynoise*np.sqrt(skylevels)\n",
    "\n",
    "#thresholds=[threshold]*len(science_reduced)\n",
    "minsize=2\n",
    "catalog={'x':[],'y':[]}\n",
    "xc_all,yc_all,xs_all,ys_all=[],[],[],[]\n",
    "figure(figsize=(15,6))\n",
    "for i in range(len(science_reduced)):\n",
    "    xfoo,yfoo,xsfoo,ysfoo=find_object_centroids_filterbysize(science_reduced[i],thresholds[i],minsize)\n",
    "    xc_all.append(xfoo)\n",
    "    yc_all.append(yfoo)\n",
    "    xs_all.append(xsfoo)\n",
    "    ys_all.append(ysfoo)\n",
    "    subplot(121)\n",
    "    plot(xfoo,yfoo,'o')\n",
    "    subplot(122)\n",
    "    plot(xfoo,yfoo,'.')\n",
    "    axis([0,400,600,1000])\n",
    "subplot(121)\n",
    "title('all objects found in all frames')\n",
    "subplot(122)\n",
    "title('zoomed in to illustrate dithering')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's make a little definition to find all matching objects given two frame's object centroids. If objects are chosen carefully, this can give us a rough offset between the frames, as is shown in the histogram below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_closest(xc0,yc0,xc1,yc1,dr):\n",
    "    nobjs1=len(xc1)\n",
    "    x_off,y_off=[],[]\n",
    "    for i in range(nobjs1):\n",
    "        poss_match=np.where(np.sqrt((xc1[i]-xc0)**2+(yc1[i]-yc0)**2)<dr)[0]  # for each object in the second catalog, \n",
    "        x_off.extend([(xc1[i]-xc0[j]) for j in poss_match])                  #  find matches within a radius dr\n",
    "        y_off.extend([(yc1[i]-yc0[j]) for j in poss_match])\n",
    "    x_off=np.array(x_off)\n",
    "    y_off=np.array(y_off)\n",
    "    \n",
    "    n_xoff,xfoo=np.histogram(x_off,bins=dr*2,range=[-dr,dr])   # histogram all the offsets to find the maximum value\n",
    "    n_yoff,yfoo=np.histogram(y_off,bins=dr*2,range=[-dr,dr])   #  which corresponds to the rough offset between frames\n",
    "    x_peak=(xfoo[where(n_xoff==np.max(n_xoff))])[0]+(xfoo[1]-xfoo[0])/2.\n",
    "    y_peak=(yfoo[where(n_yoff==np.max(n_yoff))])[0]+(yfoo[1]-yfoo[0])/2.   # (note addition of half bin width)\n",
    "    return x_off,y_off,x_peak,y_peak\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "secondnum=0   #change this to be the second frame you want to see the offsets for\n",
    "dr=60\n",
    "xc0,yc0,xc1,yc1=xc_all[0],yc_all[0],xc_all[secondnum],yc_all[secondnum]\n",
    "xoff,yoff,xpeak,ypeak=find_closest(xc0,yc0,xc1,yc1,dr)\n",
    " \n",
    "    \n",
    "hist(xoff,histtype='step',label='x offset',range=[-dr,dr],bins=dr,color='r')\n",
    "hist(yoff,histtype='step',label='y offset',range=[-dr,dr],bins=dr,color='b')\n",
    "\n",
    "axvline(xpeak,color='r')\n",
    "axvline(ypeak,color='b')\n",
    "\n",
    "xlabel('Nearest object centroid offset [pix]',fontsize=20)\n",
    "ylabel('Number of objects',fontsize=20)\n",
    "title('X/Y shift between frames',fontsize=25)\n",
    "\n",
    "figure(figsize=(10,10))\n",
    "plot(xc0,yc0,'g.')\n",
    "plot(xc1-xpeak,yc1-ypeak,'o',mfc='None')\n",
    "\n",
    "#axis([100,400,100,400])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Going a little further than the simple offsets above, iterate on this process to find the overall shifts down to subpixel accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_frame_shifts(x0,y0,x1,y1,dr0,nsteps):    #like the def above, take in two sets of coordinates\n",
    "    xshifts,yshifts=0,0\n",
    "    drs=[dr0,20,10,5,2.5,1.25]\n",
    "    for i in range(nsteps):\n",
    "        dr=dr0/(1.+i)      # slowly reduce the matching radius, to get rid of outliers\n",
    "        xoff,yoff,xpeak,ypeak=find_closest(x0,y0,x1-xshifts,y1-yshifts,dr)\n",
    "        #print xoff,yoff\n",
    "        n_xoff,xfoo=np.histogram(xoff,bins=50,range=[-dr,dr])\n",
    "        n_yoff,yfoo=np.histogram(yoff,bins=50,range=[-dr,dr])\n",
    "        #axvline(xpeak)\n",
    "        print (xpeak)\n",
    "        if i==0:\n",
    "            xshift,yshift=xpeak,ypeak    # the first rough offset estimate is the peak of the offset histogram\n",
    "        else:                            # successive offsets are found by taking the median value of the remainder\n",
    "            xshift,yshift=np.median(xoff[np.abs(xoff)<dr/2.]),np.median(yoff[np.abs(yoff)<dr/2.])\n",
    "        xshifts+=xshift        # add in each successive offset to the total\n",
    "        yshifts+=yshift\n",
    "        print (dr,xshifts,yshifts)\n",
    "        #plot(xshifts,yshifts,'o')\n",
    "    hist(xoff,histtype='step',color='r',bins=50)\n",
    "    hist(yoff,histtype='step',color='b',bins=50)\n",
    "    #plot(yfoo[1:],n_yoff,'b')\n",
    "    axvline(xshift,color='r')\n",
    "    axvline(yshift,color='b')\n",
    "    return xshifts,yshifts\n",
    "\n",
    "def find_closest(xc0,yc0,xc1,yc1,dr):\n",
    "    nobjs1=len(xc1)\n",
    "    x_off,y_off=[],[]\n",
    "    for i in range(nobjs1):\n",
    "        poss_match=np.where(np.sqrt((xc1[i]-xc0)**2+(yc1[i]-yc0)**2)<dr)[0]  # for each object in the second catalog, \n",
    "        x_off.extend([(xc1[i]-xc0[j]) for j in poss_match])                  #  find matches within a radius dr\n",
    "        y_off.extend([(yc1[i]-yc0[j]) for j in poss_match])\n",
    "    x_off=np.array(x_off)\n",
    "    y_off=np.array(y_off)\n",
    "    \n",
    "    n_xoff,xfoo=np.histogram(x_off,bins=int(dr*2),range=[-dr,dr])   # histogram all the offsets to find the maximum value\n",
    "    n_yoff,yfoo=np.histogram(y_off,bins=int(dr*2),range=[-dr,dr])   #  which corresponds to the rough offset between frames\n",
    "    x_peak=(xfoo[where(n_xoff==np.max(n_xoff))])[0]+(xfoo[1]-xfoo[0])/2.\n",
    "    y_peak=(yfoo[where(n_yoff==np.max(n_yoff))])[0]+(yfoo[1]-yfoo[0])/2.   # (note addition of half bin width)\n",
    "    return x_off,y_off,x_peak,y_peak\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform this on the first and last images, to test the concept. The definition above also produces a histogram which can be used to ensure the algorithm is working properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "firstnum,secondnum=0,0   #two different numbers corresponding to different frames\n",
    "dr=60\n",
    "xc0,yc0,xc1,yc1=xc_all[firstnum],yc_all[firstnum],xc_all[secondnum],yc_all[secondnum]\n",
    "find_frame_shifts(xc0,yc0,xc1,yc1,dr,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now deploy the offset finder on all reduced images, relative to the first one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xshifts,yshifts=np.zeros(len(science_reduced)),np.zeros(len(science_reduced))\n",
    "for secondnum in range(1,len(science_reduced)):\n",
    "    xshifts[secondnum],yshifts[secondnum]=find_frame_shifts(xc_all[0],yc_all[0],xc_all[secondnum],yc_all[secondnum],dr,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xshifts,yshifts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use scipy's interpolation shifting algo to shift each reduced image by the negative of the offsets found above. This should match them all up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape(science_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nzoom=4\n",
    "resampled=np.zeros((len(science_reduced),1024*nzoom,1024*nzoom))\n",
    "for k in range(len(science_reduced)):\n",
    "    for i in range(1024):\n",
    "        for j in range(1024):\n",
    "            resampled[k,i*nzoom:(i+1)*nzoom,j*nzoom:(j+1)*nzoom]=science_reduced[k,i,j]\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "science_shifted_resampled=np.array([snd.interpolation.shift(resampled[i],[-yshifts[i]*nzoom,-xshifts[i]*nzoom],order=3) for i in range(0,len(resampled))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fits.writeto(rootdir+thefilt+'-median-resampled.fits',np.median(science_shifted_resampled,axis=0),clobber='True')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "science_shifted_rescaled=np.array([snd.interpolation.shift(science_reduced[i],[-yshifts[i],-xshifts[i]],order=5)-skylevels[i] for i in range(0,len(science_reduced))])\n",
    "stackedimg=np.median(science_shifted_rescaled,axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display the median of the stacked image to ensure it worked okay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure(figsize=(14,12))\n",
    "title('Median stacked '+thefilt+' image',fontsize=10)\n",
    "imshow(stackedimg,cmap=cm.Greys,vmin=0,vmax=20*np.sqrt(median(skylevels)))\n",
    "colorbar()\n",
    "#plt.axis([200,700,200,700])\n",
    "fits.writeto(rootdir+thefilt+'-median.fits',stackedimg,clobber=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making an RGB image (aka align three images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgbroot='/home/andrew/Pictures/20180504-Hutchison_Hamburglar/M66/'\n",
    "rimg=fits.getdata(rgbroot+'00000086.NGC3627-R-reduced.fits')\n",
    "gimg=fits.getdata(rgbroot+'00000088.NGC3627-V-reduced.fits')\n",
    "bimg=fits.getdata(rgbroot+'00000087.NGC3627-B-reduced.fits')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nstd_aboveskynoise=6\n",
    "minsize=2\n",
    "skylevel_r,skylevel_g,skylevel_b=np.median(rimg[rimg>0]),np.median(gimg[gimg>0]),np.median(bimg[bimg>0])\n",
    "\n",
    "xr,yr,xsfoo,ysfoo=find_object_centroids_filterbysize(rimg,skylevel_r+nstd_aboveskynoise*np.sqrt(skylevel_r),minsize)\n",
    "xg,yg,xsfoo,ysfoo=find_object_centroids_filterbysize(gimg,skylevel_g+nstd_aboveskynoise*np.sqrt(skylevel_g),minsize)\n",
    "xb,yb,xsfoo,ysfoo=find_object_centroids_filterbysize(bimg,skylevel_b+nstd_aboveskynoise*np.sqrt(skylevel_b),minsize)\n",
    "\n",
    "\n",
    "plot(xr,yr,'ro',alpha=.4)\n",
    "plot(xg,yg,'go',alpha=.4)\n",
    "plot(xb,yb,'bo',alpha=.4)\n",
    "plt.figure()\n",
    "plot(xr,yr,'ro',alpha=.4)\n",
    "plot(xg,yg,'go',alpha=.4)\n",
    "plot(xb,yb,'bo',alpha=.4)\n",
    "plt.axis([100,400,600,900])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dr=10\n",
    "x_off_rb,y_off_rb=find_frame_shifts(xr,yr,xb,yb,dr,2)\n",
    "x_off_rg,y_off_rg=find_frame_shifts(xr,yr,xg,yg,dr,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure(figsize=(10,10))\n",
    "plot(xr,yr,'ro',alpha=.4)\n",
    "plot(xg-x_off_rg,yg-y_off_rg,'go',alpha=.4)\n",
    "plot(xb-x_off_rb,yb-y_off_rb,'bo',alpha=.4)\n",
    "#axis([500,700,200,400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgbroot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_shifted=snd.interpolation.shift(gimg,[-y_off_rg,-x_off_rg],order=1)\n",
    "fits.writeto(rgbroot+'V-median-shifted.fits',g_shifted,clobber='True')\n",
    "\n",
    "b_shifted=snd.interpolation.shift(bimg,[-y_off_rb,-x_off_rb],order=1)\n",
    "fits.writeto(rgbroot+'B-median-shifted.fits',b_shifted,clobber='True')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scalesqrt(inputArray, scale_min=None, scale_max=None):\n",
    "    \"\"\"Performs sqrt scaling of the input numpy array.\"\"\"\n",
    "\n",
    "    imageData=numpy.array(inputArray, copy=True)\n",
    "\n",
    "    imageData = imageData.clip(min=scale_min, max=scale_max)\n",
    "    imageData = imageData - scale_min\n",
    "    indices = numpy.where(imageData < 0)\n",
    "    imageData[indices] = 0.0\n",
    "    imageData = numpy.sqrt(imageData)\n",
    "    imageData = imageData / math.sqrt(scale_max - scale_min)\n",
    "\n",
    "    return imageData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in three images for the r,g,b array. Each of these has been reduced, stacked, and shifted/rotated to be on a common coordinate system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgbroot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rimg=fits.getdata(rgbroot+'00000086.NGC3627-R-reduced.fits')\n",
    "gimg=fits.getdata(rgbroot+'V-median-shifted.fits')\n",
    "bimg=fits.getdata(rgbroot+'B-median-shifted.fits')\n",
    "\n",
    "rgbstack=[rimg,gimg,bimg]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do a rescaling of the image data for the purposes of making the RGB image (which needs values between 0 and 8 bits (0-255). I use the sqrt scaling used in the definition above, with a min and max defined by 0 and some number of std deviations above the sky noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nstd=11   # number of standard deviations above sky noise to call an RGB pixel=255\n",
    "rgbimg=np.zeros((1024,1024,3))\n",
    "\n",
    "for i in range(3):\n",
    "    onecolor=rgbstack[i]\n",
    "    colorstd,colormed=np.std(onecolor[onecolor>10]),np.median(onecolor[onecolor>10])\n",
    "    scale_min,scale_max=colormed,nstd*colorstd\n",
    "    rgbimg[:,:,i]=scalesqrt(onecolor, scale_min=scale_min, scale_max=scale_max)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finally, display our RGB image with imshow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure(figsize=(10,10))\n",
    "imshow(rgbimg,interpolation='None')\n",
    "#axis([150,800,50,800])\n",
    "axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do a calibration  in the V band, using one exposure of the Landolt star (reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgbroot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hflatmed=fits.getdata(rootdir+'H-a-median_flat.fits')\n",
    "#median_bias=fits.getdata(rootdir+'median_bias.fits')\n",
    "\n",
    "calibfilename=rgbroot+'00000088.NGC3627-V-reduced.fits'#[rootdir+'20160517/Calibration/Feige66.00000034.M_51.FIT']\n",
    "vcalib=fits.getdata(calibfilename)#reduce_raw_science_frames(calibfilename,median_bias,hflatmed,median_bias)[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgnum=0\n",
    "nstd_aboveskynoise=12\n",
    "threshold=skylevels[imgnum]+nstd_aboveskynoise*np.sqrt(skylevels[imgnum])   # decide on a threshold using the sky noise\n",
    "minsize=2\n",
    "\n",
    "xfoo,yfoo,xsfoo,ysfoo=find_object_centroids_filterbysize(vcalib,threshold,minsize)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(20,20))\n",
    "plt.imshow(vcalib,cmap=cm.Greys,vmin=0,vmax=1.5*threshold)\n",
    "plt.plot(xfoo,yfoo,'rs',mfc='None',markersize=20,markeredgecolor='b',markeredgewidth=2)\n",
    "for x,y,i in zip(xfoo,yfoo,range(len(xfoo))): plt.text(x+10,y+10,str(i),fontsize=20,color='b')\n",
    "axis([0,1024,0,1024])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure(figsize=(20,8))\n",
    "subplot(121)\n",
    "foonum=8\n",
    "yc,xc=int(xfoo[foonum]),int(yfoo[foonum])  #if using DS9 coordinates, be sure to to x->y and y->x  for translating to numpy array coords\n",
    "wid=30\n",
    "imshow(vcalib,vmin=700,vmax=1200,cmap=cm.gray_r,origin='lower')\n",
    "cal_snip=vcalib[xc-wid:xc+wid,yc-wid:yc+wid]\n",
    "subplot(122)\n",
    "imshow(cal_snip,vmin=1000,vmax=2000,cmap=cm.gray,origin='lower'),colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot a histogram of the background pixel values and take the median to find the sky level to subtract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist(cal_snip.flatten(),bins=100,range=[500,1500],histtype='stepfilled',color='g',alpha=.3)\n",
    "xlabel('ADU of background')\n",
    "ylabel('Number of pixels')\n",
    "m,s=mean(cal_snip[cal_snip<1000]),std(cal_snip[cal_snip<1000])\n",
    "axvline(m-s),axvline(m+s),axvline(m,color='r')\n",
    "print m,s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the centroid of the little standard star snippet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xc,yc=0,0\n",
    "pixsum=0\n",
    "nx,ny=shape(cal_snip)\n",
    "for i in range(nx):\n",
    "    for j in range(ny):\n",
    "        if cal_snip[j,i]>m+s:\n",
    "            xc+=cal_snip[j,i]*i\n",
    "            yc+=cal_snip[j,i]*j\n",
    "            pixsum+=cal_snip[j,i]\n",
    "xc,yc=xc/pixsum,yc/pixsum\n",
    "print (xc,yc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display the apertures centered around the standard star centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dr=12\n",
    "r=arange(0,30,dr)\n",
    "phi=linspace(0,2*pi,1000)\n",
    "\n",
    "\n",
    "figure(figsize=(8,6))\n",
    "pcolor(cal_snip,vmin=500),colorbar()\n",
    "plot(xc,yc,'wo')\n",
    "for i in range(len(r)): plot(r[i]*cos(phi)+xc,r[i]*sin(phi)+yc,'r',alpha=.8)\n",
    "#axis([25,80,30,80])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sum up the counts and number of pixels in the background and star annuli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_flux=zeros(len(r))\n",
    "ann_npix=zeros(len(r))\n",
    "for i in range(nx):\n",
    "    for j in range(ny):\n",
    "        rdist=sqrt((xc-i)**2+(yc-j)**2)\n",
    "        for k in range(len(r)):\n",
    "            if ((rdist>r[k]) and (rdist<r[k]+dr)):\n",
    "                ann_flux[k]+=cal_snip[j,i]\n",
    "                ann_npix[k]+=1\n",
    "\n",
    "\n",
    "print (r,ann_flux-ann_npix*m,(ann_flux-m*ann_npix)/ann_npix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in the exposure time and airmass for that calibration frame, and find the zeropoint offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calibfilename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cal_exptime=float(fits.getheader(calibfilename)['EXPTIME'])\n",
    "cal_airmass=float(fits.getheader(calibfilename)['AIRMASS'])\n",
    "cal_vflux=ann_flux[0]-ann_npix[0]*m\n",
    "print (\"Exposure time is: \"+ str(cal_exptime))\n",
    "print (\"Flux is: \" +str(cal_vflux))\n",
    "\n",
    "cal_vmag=-2.5*log10(cal_vflux/cal_exptime)\n",
    "print (\"Instrumental magnitude is, -2.5*log10(flux/time): \" + str(cal_vmag))\n",
    "\n",
    "cal_mag_ext=.15*cal_airmass\n",
    "print (\"The airmass is: \" +str(cal_airmass)+\", so given .15 magnitudes/airmass extinction, there are: \" +str(cal_mag_ext))\n",
    "print (\" magnitudes of extincion.\")\n",
    "\n",
    "cal_vmag0=cal_vmag+cal_mag_ext\n",
    "print (\"So our final instrum. magnitude in V, removing atmospheric effects, is: \" +str(cal_vmag0))\n",
    "\n",
    "\n",
    "landolt_vmag=9.86\n",
    "cal_vzpt=landolt_vmag-cal_vmag0\n",
    "print (\"Landolt says SA 103-302 is magnitude 9.86, so our zeropoint is then: \" +str(cal_vzpt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now perform aperture photometry on the object image, and convert to magnitudes per sq. arcsec using the calibration from above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a series of radial apertures in which to measure flux, and overplot them on the image to analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dr=10\n",
    "objnum=4\n",
    "wid=100\n",
    "r=arange(0,wid,dr)\n",
    "phi=linspace(0,2*pi,1000)\n",
    "xc,yc=int(xfoo[objnum]),int(yfoo[objnum])  #int for using as numpy array coordinates\n",
    "#wid=100\n",
    "\n",
    "#v_med=vcalib#fits.getdata(rgbroot+'V-median-shifted.fits')\n",
    "figure(figsize=(8,8))\n",
    "#object_vsnip=vcalib[xc-wid:xc+wid,yc-wid:yc+wid]\n",
    "imshow(vcalib,vmin=m,vmax=m+3*s,cmap=cm.Greys_r),colorbar()\n",
    "\n",
    "#plot(xc,yc,'wo')\n",
    "for i in range(len(r)): plot(r[i]*cos(phi)+xc,r[i]*sin(phi)+yc,'r',alpha=.8)\n",
    "axis([xc-wid*2,xc+wid*2,yc-wid*2,yc+wid*2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is the background level in the object image? Take the median in a limited range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist(vcalib.flatten(),range=[800,1000],bins=100)\n",
    "xlabel('ADU value')\n",
    "ylabel('Number of pixels')\n",
    "title('Histogram of sky pixels in the field')\n",
    "bkg=median(vcalib)\n",
    "axvline(bkg,color='r')\n",
    "print (bkg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  For each radial aperture, sum up the counts and number of pixels inside"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx,ny=shape(vcalib)\n",
    "ann_flux=zeros(len(r))\n",
    "ann_npix=zeros(len(r))\n",
    "# this loops over every pixel in the image (which is a rather brute force method)\n",
    "for i in range(nx):\n",
    "    for j in range(ny):\n",
    "        rdist=sqrt((xc-i)**2+(yc-j)**2)\n",
    "        for k in range(len(r)):\n",
    "            if ((rdist>r[k]) and (rdist<r[k]+dr)):     # if the pixel is insize the kth aperture, add it to the tally\n",
    "                ann_flux[k]+=vcalib[j,i]\n",
    "                ann_npix[k]+=1\n",
    "\n",
    "\n",
    "print (r,ann_flux-bkg*ann_npix,(ann_flux-bkg*ann_npix)/ann_npix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now calculate the surface brightness, in calibrated units of magnitudes per square arcsecond. This requires knowledge of the fluxes in radial apertures (and the number of pixels in each aperture), the background, the exposure time, the pixel scale, and the airmass and calibration zeropoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objectairmass=float(fits.getheader(calibfilename)['AIRMASS'])\n",
    "exptime=float(fits.getheader(calibfilename)['EXPTIME'])\n",
    "pixscale=24*60/1024.\n",
    "print (\"The pixel scale is: \"+str(pixscale)+ \", airmass is: \" + str(objectairmass))\n",
    "\n",
    "v_surfbright=-2.5*log10((ann_flux-bkg*ann_npix)/exptime)+2.5*log10(ann_npix*pixscale**2)+cal_vzpt+.15*objectairmass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure(figsize=(12,6))\n",
    "plot(r*pixscale,v_surfbright,linewidth=4,alpha=.5)\n",
    "axis([0,1.4*wid,24,17])\n",
    "xlabel('Radius [arcsec]',fontsize=20)\n",
    "ylabel('$\\\\mu$, surface brightness [mag/$arcsec^2$]',fontsize=20)\n",
    "title('V band Radial surface brightness profile of object',fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
